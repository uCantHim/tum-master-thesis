\chapter{Implementation}\label{chapter:implementation}

\section{Local Discreteness}\label{sec:impl:local_discreteness}

Requiring a tested translator to satisfy local discreteness is imperative to verify whether $P_X \equiv E_{X \rightarrow
Y}(P_X)$. This is because, if this requirement weren't assumed, a verifier would either have to hard-code the result of
comparing every possible program of $X$ to every possible program of $Y$ (which is obvious nonsense as both of these
sets are infinitely large) or be another sort of `magical' algorithm that is not conceivable by human reason. This
argument simultaneously shows that every implementation of a binary translator \textbf{must necessarily} be locally
discrete for the same reasons.

However, when we use the definition of program equivalence to transform the problem into $P_X(S) = [E_{X \rightarrow
Y}(P_X)](S)$, the global comparison of result states becomes possible again. While this removes the theoretical
necessity for the local discreteness assumption, it is still practically useful, if not essential. An outcome of
comparing result states of full program executions would be a statement like "The program's translation is erroneous".
This is too general of an assertion to be useful to developers. When we instead use local discreteness and check for all
intermediate states whether $S_i = S^E_i$ (where $S_i = x_{i-1}(S_{i-1})$ and $S^E_i = E_{X \rightarrow
Y}(x_{i-1})(S^E_{i-1})$), we can generate much more detailed information, such as "Instruction $x_i$ is translated
incorrectly because $S_i \neq S^E_i$". This is exactly what Focaccia wants to achieve.

\section{Comparing Program States}\label{sec:impl:comparison}

A naive comparison algorithm works as follows: We run $P_X$ on one starting state $S$ and the translation $E_{X
\rightarrow Y}(P_X)$ on another possibly different starting state $S'$, during which we record all intermediate states
$S_i$ and $S^E_i$ (which are the result states from applying $x_i$ and $E_{X \rightarrow Y}(x_i)$ to $S_{i-1}$ and
$S'_{i-1}$, respectively).

As was hinted in section \ref{sec:intro:focaccia}, comparing program states for the sake of verifying semantic program
equivalence is more complex than comparing register and memory content for equality; that is because the starting states
for the execution of programs are not always equal. Instead of comparing $P_X(S) = P_Y(S')$, which does \textbf{not}
imply $P_X \equiv P_Y$ if $S \neq S'$, the comparison must take into account the initial difference $\Delta_S = S - S'$
and calculate a state equivalence $P_X(S) \equiv P_Y(S') \implies P_X \equiv P_Y$ with respect to it. This is the chief
nontriviality that Focaccia's algorithm solves.

Possible contributing factors to $\Delta_S$ (subsequently collectivized as a general \textit{difference in environment})
include:

\begin{enumerate}
    \item Different stack pointers.
    \item Different addresses of heap allocations.
    \item Different argument-, environment-, and auxiliary vectors.
\end{enumerate}

The way we incorporate effectively random permutations of starting states into the algorithm is by re-introducing
information about the guest instruction $x$ to the algorithm, which, in order to simplify the problem, we have discarded
when we transformed the central question from $x \equiv E_{X \rightarrow Y}(x)$ to $x(S) = [E_{X \rightarrow Y}(x)](S)$.
Instead of running guest program and translation in parallel and comparing their intermediate states, only run the
translation $E_{X \rightarrow Y}(P_X)$ on a start state $S^E_1$, thereby obtaining the translation's intermediate states
$S^E_i$. Then, for each $S^E_i$, use the guest instruction $x_i$ to calculate a corresponding \textbf{expected state}
$S_{i+1} = x_i(S^E_i)$. These represent truth states that would result from executing $x_i$ on $S^E_i$ if $x_i$ was
implemented correctly. Finally, compare these expected states to the actual translation states: $S^E_{i+1} = S_{i+1}$.

Expressing the pre-translation program $(x_i)$ as its instructions' true functions on program states as opposed to
executing it natively on a semi-random starting state thus allows us to use the same starting state for both the
translation and the truth program at each instruction. This enables the desired equality comparison $x_i(S_i) = E_{X
\rightarrow Y}(x_i)(S_i)$. The drawback of this approach is that we now require an additional piece of information: We
need to know $x_i$.

\section{Symbolic Execution}

\subsection{Obtaining the Instruction}

In the first prototype, we used a disassembly framework to load a binary and disassemble it in its entirety. This was
slow and produced lots of unnecessary computations, so we started disassembling instructions on demand, i.e. at each
program counter only read the next instruction. This works for statically linked binaries as all information is in one
file and can be loaded from there. In the third iteration, in order to support dynamically linked programs and even
\ac{JIT} compiled code, we omit loading the binary entirely and instead read the next instruction directly from the
running program's memory; this can be either a native execution (see \ref{sec:impl:concrete_exec}) or a running
translator/emulator.

\subsection{A Symbolic Representation}

Once we have an instruction's byte code, we need to apply it to a program state.

Essentially, we rely on one translator (in this case one which translates instructions into symbolic equations) to be
implemented correctly: It is an oracle.

\subsection{Verifiying the Symbolic Execution Backend}

\section{Concrete Guidance}\label{sec:impl:concrete_exec}

\section{Trace Mismatch}\label{sec:impl:trace_mismatch}

One can imagine code that behaves effectively as the following:

\begin{lstlisting}[language=Python]
    n = random()
    if n > 0.5:
        func_a()
    else:
        func_b()
\end{lstlisting}

These situations do happen, be it during iteration over environment arrays or their content, literally deciding branches
based on randomness, or generally any branching involving nondeterministic values (networking, time, system state, â€¦). A
specific situation in which this routinely happens is the libc initialization code, where auxiliary and environment
vectors are processed. These nondeterministic mutations can cause the symbolic program trace differ from the tested
program trace.

Per-instruction symbolism cannot process these situations; the symbolic truth simply does not provide information on
instructions that were not part of its program execution. An algorithm <no local discreteness assumption could solve
this, but is not possible with symbolic exec: state explosion>

\textbf{NOTE} Can be eliminated for the special case of online emulator verification. We could implement a minimal
custom protocol as a replacement for the GDB-server protocol and provide a general online verification algorithm for
emulators that implement this protocol specifically for verification with Focaccia. This algorithm would give the
highest-quality results that Focaccia is able to calculate.



% APPROACH
%
%  - systematic!
%  - we don't want to write tests
%  - fuzzing has more setup work, is harder to use
%
% chapter 12 virtual machines popek & goldberg
%
% establishing V(S_j)
