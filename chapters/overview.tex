\chapter{Overview}

The value of binary translation technologies has been firmly established~\cite{altman2000welcome, sites1993binary,
probst2002dynamic}. These are large programs that additionally deal in an inherently complex problem domain, causing
their development to be accordingly difficult. We want to aid this endeavour by \textbf{testing} binary translators,
particularly emulators and dynamic binary translators---the latter being essentially an optimization of the former.

Testing means to evaluate whether a system meets its originally specified requirements~\cite{jamil2016software_testing}.
Possible specification requirements for emulators might be performance or feature size, but the specific ubiquitous
requirement for emulators (and really any software) that we want to test for is \textit{correctness}. As formalized in
section~\ref{sec:definitions}, the fundamental definition of correctness for binary translators is semantic equivalence
between input- and output programs, that is, of the translated program and the translation.

% Traditional approach and its problems
The traditional and most widely used way to test software, called unit testing, requires developers to divide the tested
entity into atomic, self-contained units/functions (test cases), collect an as exhaustive as possible list of inputs to
that unit, and compare the unit's output for all inputs to their respective expected outputs. This approach is usable
and popular, though it carries with it significant shortcomings and difficulties:

\begin{itemize}
    \item The procedure is not systematic. Ultimately, test quality depends on the developer's abilities and
        whim---"identifying which code to test" and the \textit{oracle problem} have been reported as major
        difficulties in writing unit tests~\cite{Daka+2014UnitTestingSurvey}.
    \item The isolated nature of unit tests means that units have to be isolated in the first place, which is often not
        trivial.
    \item The expected value against which a test case's output is checked is not necessarily reliable as it is subject
        to human error just as much as the code that is being tested.
    \item Manual work is time consuming.
\end{itemize}

% How exactly our task is particularly difficult
Many of these problems are amplified by the complexity of an emulator's domain, where the test development procedure
could look like the following: We utilise the local discreteness property of the emulator (see
section~\ref{sec:definitions}) and write test cases for each instruction for each ISA that the emulator supports. We let
the emulator simulate an instruction for a number of different operands, which we obtain by thinking about classes of
equivalent values and choosing an exhaustive list of representatives and corner cases, and check for each
instruction-operand-combination whether the emulator's state after the instruction has been executed is equal to the
state that we would expect it to reach, which we have calculated manually based on our understanding of the respective
instruction's semantics.

The issues at every step of this approach are glaring: Expected test truths can easily be wrong, especially when the
same developer that implemented the translation also writes the test and thus applies their own faulty understanding of
how the instruction should operate to it. Further, complex architectures like x86 can have, in addition to a vast number
of different instructions, a gigantic number of possible instruction-operand combinations for each instruction which is
unlikely to be exhausted in manually written tests; additionally, corner cases for inputs are hard to identify, the
process is excessively time consuming, and, more important than is often admitted: developers don't want to go through
all of this effort---and hence frequently just don't.

% Statement of the fact that we address these problems (at least some of them)
Many techniques have been developed to improve this process, especially on the part of \textbf{generating} test cases.
Fuzzing, where tested units are essentially supplied with randomized inputs, is a popular and successful method for
improving test coverage~\cite{Zhu+2022Fuzzing}. Another technique in this area which also relates to Focaccia, though in
a different manner, is symbolic execution. It can be employed as a formal method to generate truly exhaustive lists of
test cases by finding inputs to tested functions that cover all possible solutions for generated path
constraints~\cite{Li2011SymbexecTestGeneration}.

Focaccia, on the other hand, focuses on tackling the \textit{oracle problem}, that is the concern of generating reliable
\textit{test truths}. Special attention is paid to \textit{practical utility} in emulator development and to avoid
lengthy setup/integration work, which is a common problem of advanced automated testing technologies. Focaccia aims to
be usable with minimal setup work and provide an `out-of-the-box' experience, additionally capitalizing on a natural
occurrence of test cases: native programs.

\section{Focaccia's Approach}

% What does it do?
Focaccia implements an automatic verifier for emulators. The algorithm detects errors in an emulator's implementation by
comparing its simulated program state with a \textit{truth state} for which it implements an oracle that calculates
expected program states that should result from executing instructions correctly. It accomplishes this by employing
symbolic execution techniques to capture instructions' true semantics.

% How does it do what it does?
The primary emulator verification algorithm requires as inputs:

\begin{itemize}
    \item A concrete test trace, which is a trace of the program's execution via the tested emulator. It comprises a
        list of instructions executed and corresponding program state snapshots at each instruction, meaning the
        process's register- and memory contents.
    \item A symbolic reference trace. This is the oracle, and it is computed by Focaccia. It is a trace of the same
        program, but, instead of program state snapshots, it defines symbolic equations that encapsulate the
        corresponding instruction's \textit{correct} behaviour.
\end{itemize}

The verifier steps through the test trace and calculates for each program snapshot the truth state that \textbf{should}
result from executing the corresponding instruction on the test state; it uses the respective equation from the symbolic
trace to compute this truth. It then compares the next test state, meaning the actual state of the emulator after it
executed the instruction, to the expected truth state. The emulator's implementation of that instruction is faulty if
these states are not equal---in this case, a detailed error message is issued including the faulty instruction, the
emulator's faulty state at that point, and the correct transformation that was expected to occur.

% How to use it?
Focaccia is a command-line invocable program with a few helper tools. It takes as input a source of a concrete trace and
a source of a symbolic trace. The former is usually an emulator's log (see section~\ref{sec:obtaining_snapshots} for
details on this matter). The latter is usually the traced program from which the verifier will generate the symbolic
trace. Data from these sources are used to compute the comparison described above and finally print a summary of the
results. Pre-computing symbolic traces for a program and exporting them to a file that can later be fed to the main
program for verification is also possible. Additionally, we include a helper script that records concrete traces in the
form of efficient minimal program snapshots from emulators that provide a \texttt{gdbserver}
interface~\cite{Sourceware2024GdbRemoteProtocol} (QEMU, for example).

\section{Focaccia's Position in the Software Testing Landscape}\label{sec:testing}

% Categorization
In the domain of automated testing, our specific interest can be categorized as \textit{correctness testing}. We can
further refine the classification by considering that the algorithm effectively compares the program's output to an
expected oracle-based output, with no knowledge about the tested program's internal structure: it is a \textit{black
box} approach~\cite{sawant2012software}. It is noteworthy that symbolic/concolic execution is usually used as a
white-box technique to prove properties of tested code, but Focaccia uses it to establish correctness not of the tested
program itself, but of the tested program's \textbf{output}, because, in the special case of emulators, the output
\textbf{is itself a program}. Thus, it inherits many of the common problems of black box testing:

% Inherent disadvantages
\begin{itemize}
    \item The set of testable input permutations is very restricted because test cases are created manually.
    \item Tests are unlikely to establish exhaustive certainty about the subject's correctness.
    \item Does not inherently maximize code-/branch coverage.
\end{itemize}

% Inherent advantages
On the other hand, our approach does not require extensive setup work, thereby facilitating easy integration into the
development workflow, is applicable to complex real-world test cases (particularly whole programs), and gives detailed
information at the semantic level of the emulator's problem domain. It is thereby clearly distinguished from the unit
testing approach because it establishes correctness on the higher level of macroscopic program function.

% Areas that are entirely untouched by Focaccia
Although Focaccia covers the oracle problem, the necessity of generating the test cases themselves persists. It is
therefore combinable with many of the existing techniques, paradigms, and structured approaches to generate test
cases like equivalence partitioning, fuzzing, et cetera~\cite{jan2016innovative, yu2011robust_planning}.

%Combining fuzzing with concolic execution (2021):~\cite{Borzacchiello2021Fuzzolic}.
