\chapter{Future Work}\label{chapter:future_work}

\section{The Oracle Problem}

Focaccia chooses symbolic execution as a tool to implement an oracle that predicts the correct behaviour of
instructions. The evaluation has shown that this approach is theoretically servicable, though susceptible to the same
problems as those that it tries to solve: Implementing correct representations of instruction semantics is difficult and
prone to mistake.

A possible solution is to look for a more complete symbolic execution backend. Unfortunately, we decided early on in the
development process that an abstraction layer for multiple interchangeable symbolic execution backends was not
necessary. This is a misjudgement in hindsight and will incur some extra work to implement the mechanism now, though it
is certainly still possible to do so.

On the other hand, one could look into a replacement strategy for symbolic execution, as that is currently Focaccia's
dominant weakness---a theoretically more sound approach to the oracle may be required. Section~\ref{sec:comparison}
hints towards a possible alternative: generate a small program that sets up processor and memory state, runs an
instruction on it, and then reads back the result. It uses a hardware implementation as the oracle, which undergoes much
more rigorous testing than a software emulator, or may even be set forth as the \textbf{definition} of correctness,
depending on context. One may be able to re-use the existing reproducer's mechanism (implemented by Alp Berkman on top
of Focaccia), which performs pretty much exactly this task.

\section{Environments}

Another one of Focaccia's struggles is environment difference between the process that guides symbolic execution and the
tested emulator. Advanced strategies either to ensure equal environments for both executions or to minimize the
difference's impact can improve the quality of verification results.

\section{Systematic Test Case Generation}

Focaccia is highly automatic, though still works on specific test cases, meaning the approach is not much more
systematic than traditional unit testing---it merely tests the program on a different level. Any technique that
generates inputs to it systematically can drastically raise the tests' exhaustiveness. The reproducer mentioned above
could again find use here: It can be extended to generate not only one minimal reproducing program for each bug that
Focaccia finds (which is its current purpose), but systematically explore the range of inputs to the faulty instruction
and generate exhaustive test cases/programs for it.
