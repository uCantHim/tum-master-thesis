@book{latex,
  title = {LaTeX : A Documentation Preparation System User's Guide and Reference Manual},
  publisher = {Addison-Wesley Professional},
  year = {1994},
  author = {Leslie Lamport}
}

@misc{Z3prover2024Mar,
  author = {Z3prover},
  title = {{z3}},
  journal = {GitHub},
  year = {2024},
  month = mar,
  note = {[Online; accessed 11. Mar. 2024]},
  url = {https://github.com/Z3Prover/z3}
}

@Inbook{Steinhöfel2022,
  author="Steinh{\"o}fel, Dominic",
  editor="Ahrendt, Wolfgang
  and Beckert, Bernhard
  and Bubel, Richard
  and Johnsen, Einar Broch",
  title="Symbolic Execution: Foundations, Techniques, Applications, and Future Perspectives",
  bookTitle="The Logic of Software. A Tasting Menu of Formal Methods: Essays Dedicated to Reiner H{\"a}hnle on the Occasion of His 60th Birthday",
  year="2022",
  publisher="Springer International Publishing",
  address="Cham",
  pages="446--480",
  abstract="Symbolic Execution (SE) enables a precise, deep program exploration by executing programs with symbolic inputs. Traditionally, the SE community is divided into the rarely interacting sub-communities of bug finders and program provers. This has led to independent developments of related techniques, and biased surveys and foundational papers. As both communities focused on their specific problems, the foundations of SE as a whole were not sufficiently studied. We attempt an unbiased account on the foundations, central techniques, current applications, and future perspectives of SE. We first describe essential design elements of symbolic executors, supported by implementations in a digital companion volume. We recap a semantic framework, and derive from it a---yet unpublished---automatic testing approach for SE engines. Second, we introduce SE techniques ranging from concolic execution over compositional SE to state merging. Third, we discuss applications of SE, including test generation, program verification, and symbolic debugging. Finally, we address the future. Google's OSS-Fuzz project routinely detects thousands of bugs in hundreds of major open source projects. What can symbolic execution contribute to future software verification in the presence of such competition?",
  isbn="978-3-031-08166-8",
  doi="10.1007/978-3-031-08166-8_22",
  url="https://doi.org/10.1007/978-3-031-08166-8_22"
}

@inproceedings{shoshitaishvili2016state,
  title={{SoK: (State of) The Art of War: Offensive Techniques in Binary Analysis}},
  author={Shoshitaishvili, Yan and Wang, Ruoyu and Salls, Christopher and
          Stephens, Nick and Polino, Mario and Dutcher, Audrey and Grosen, John and
          Feng, Siji and Hauser, Christophe and Kruegel, Christopher and Vigna, Giovanni},
  booktitle={IEEE Symposium on Security and Privacy},
  year={2016}
}

@misc{AngrWebsite2024Mar,
  title = {{angr}},
  year = {2024},
  month = mar,
  note = {[Online; accessed 25. Mar. 2024]},
  url = {https://angr.io}
}

@article{desclaux2012miasm,
  title={Miasm: Framework de reverse engineering},
  author={Desclaux, Fabrice},
  journal={Actes du sstic. sstic},
  year={2012}
}

@misc{cea-sec2024Mar,
  author = {cea-sec},
  title = {{miasm}},
  year = {2024},
  month = mar,
  note = {[Online; accessed 25. Mar. 2024]},
  url = {https://github.com/cea-sec/miasm}
}

@INPROCEEDINGS{jamil2016software_testing,
  author={Jamil, Muhammad Abid and Arif, Muhammad and Abubakar, Normi Sham Awang and Ahmad, Akhlaq},
  booktitle={2016 6th International Conference on Information and Communication Technology for The Muslim World (ICT4M)},
  title={Software Testing Techniques: A Literature Review},
  year={2016},
  volume={},
  number={},
  pages={177-182},
  keywords={Software;Software testing;Automation;Computer bugs;Quality assurance;Planning;Testing Methodologies;Software Testing Life Cycle;Testing Frameworks;Automation Testing;Test Driven Development;Test optimisation;Quality Metrics},
  doi={10.1109/ICT4M.2016.045}
}

@article{sawant2012software,
  title={Software testing techniques and strategies},
  author={Sawant, Abhijit A and Bari, Pranit H and Chawan, PM},
  journal={International Journal of Engineering Research and Applications (IJERA)},
  volume={2},
  number={3},
  pages={980--986},
  year={2012}
}

@article{jan2016innovative,
  title={An innovative approach to investigate various software testing techniques and strategies},
  author={Jan, S Roohullah and Shah, S Tauhid Ullah and Johar, Z Ullah and Shah, Yasin and Khan, Fazlullah},
  journal={Int. J. Sci. Res. Sci. Eng. Technol},
  volume={2},
  number={2},
  pages={682--689},
  year={2016}
}

@article{yu2011robust_planning,
  author={Yu, Han and Chung, C. Y. and Wong, K. P.},
  journal={IEEE Transactions on Power Systems},
  title={Robust Transmission Network Expansion Planning Method With Taguchi's Orthogonal Array Testing},
  year={2011},
  volume={26},
  number={3},
  pages={1573-1580},
  keywords={Testing;Planning;Arrays;Renewable energy resources;Robustness;Optimization;Robust design;Taguchi's orthogonal array testing;transmission network expansion planning;uncertainty},
  doi={10.1109/TPWRS.2010.2082576}
}

@misc{MuslLibc2024Feb,
	title = {{musl libc}},
	year = {2024},
	month = feb,
	note = {[Online; accessed 1. Apr. 2024]},
	url = {https://musl.libc.org}
}

@misc{getauxval2024Mar,
	title = {{getauxval(3) - Linux manual page}},
	year = {2024},
	month = mar,
	note = {[Online; accessed 1. Apr. 2024]},
	url = {https://www.man7.org/linux/man-pages/man3/getauxval.3.html}
}

@article{Baldoni2018SymbexecSurvey,
  author = {Baldoni, Roberto and Coppa, Emilio and D’elia, Daniele Cono and Demetrescu, Camil and Finocchi, Irene},
  title = {A Survey of Symbolic Execution Techniques},
  year = {2018},
  issue_date = {May 2019},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {51},
  number = {3},
  issn = {0360-0300},
  url = {https://doi.org/10.1145/3182657},
  doi = {10.1145/3182657},
  abstract = {Many security and software testing applications require checking whether certain properties of a program hold for any possible usage scenario. For instance, a tool for identifying software vulnerabilities may need to rule out the existence of any backdoor to bypass a program’s authentication. One approach would be to test the program using different, possibly random inputs. As the backdoor may only be hit for very specific program workloads, automated exploration of the space of possible inputs is of the essence. Symbolic execution provides an elegant solution to the problem, by systematically exploring many possible execution paths at the same time without necessarily requiring concrete inputs. Rather than taking on fully specified input values, the technique abstractly represents them as symbols, resorting to constraint solvers to construct actual instances that would cause property violations. Symbolic execution has been incubated in dozens of tools developed over the past four decades, leading to major practical breakthroughs in a number of prominent software reliability applications. The goal of this survey is to provide an overview of the main ideas, challenges, and solutions developed in the area, distilling them for a broad audience.},
  journal = {ACM Comput. Surv.},
  month = {may},
  articleno = {50},
  numpages = {39},
  keywords = {static analysis, software testing, concolic execution, Symbolic execution}
}

@article{Boyer1975Select,
 author = {Boyer, Robert S. and Elspas, Bernard and Levitt, Karl N.},
 title = {SELECT—a formal system for testing and debugging programs by symbolic execution},
 year = {1975},
 issue_date = {June 1975},
 publisher = {Association for Computing Machinery},
 address = {New York, NY, USA},
 volume = {10},
 number = {6},
 issn = {0362-1340},
 url = {https://doi.org/10.1145/390016.808445},
 doi = {10.1145/390016.808445},
 abstract = {SELECT is an experimental system for assisting in the formal systematic debugging of programs. It is intended to be a compromise between an automated program proving system and the current ad hoc debugging practice, and is similar to a system being developed by King et al. of IBM. SELECT systematically handles the paths of programs written in a LISP subset that includes arrays. For each execution path SELECT returns simplified conditions on input variables that cause the path to be executed, and simplified symbolic values for program variables at the path output. For conditions which form a system of linear equalities and inequalities SELECT will return input variable values that can serve as sample test data. The user can insert constraint conditions, at any point in the program including the output, in the form of symbolically executable assertions. These conditions can induce the system to select test data in user-specified regions. SELECT can also determine if the path is correct with respect to an output assertion. We present four examples demonstrating the various modes of system operation and their effectiveness in finding bugs. In some examples, SELECT was successful in automatically finding useful test data. In others, user interaction was required in the form of output assertions. SELECT appears to be a useful tool for rapidly revealing program errors, but for the future there is a need to expand its expressive and deductive power.},
 journal = {SIGPLAN Not.},
 month = {apr},
 pages = {234–245},
 numpages = {12},
 keywords = {Test data generation, Symbolic execution, Solution of systems of inequalities, Program verification, Program testing, Program debugging}
}

@article{King1975Effigy,
  author = {King, James C.},
  title = {A new approach to program testing},
  year = {1975},
  issue_date = {June 1975},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {10},
  number = {6},
  issn = {0362-1340},
  url = {https://doi.org/10.1145/390016.808444},
  doi = {10.1145/390016.808444},
  abstract = {The current approach for testing a program is, in principle, quite primitive. Some small sample of the data that a program is expected to handle is presented to the program. If the program produces correct results for the sample, it is assumed to be correct. Much current work focuses on the question of how to choose this sample. We propose that a program can be more effectively tested by executing it "symbolically." Instead of supplying specific constants as input values to a program being tested, one supplies symbols. The normal computational definitions for the basic operations performed by a program can be expanded to accept symbolic inputs and produce symbolic formulae as output. If the flow of control in the program is completely independent of its input parameters, then all output values can be symbolically computed as formulae over the symbolic inputs and examined for correctness. When the control flow of the program is input dependent, a case analysis can be performed producing output formulae for each class of inputs determined by the control flow dependencies. Using these ideas, we have designed and implemented an interactive debugging/testing system called EFFIGY.},
  journal = {SIGPLAN Not.},
  month = {apr},
  pages = {228–233},
  numpages = {6},
  keywords = {Symbolic interpretation, Symbolic execution, Program verification, Program testing, Program correctness}
}

@article{King1976SymbExec,
  author = {King, James C.},
  title = {Symbolic execution and program testing},
  year = {1976},
  issue_date = {July 1976},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {19},
  number = {7},
  issn = {0001-0782},
  url = {https://doi.org/10.1145/360248.360252},
  doi = {10.1145/360248.360252},
  abstract = {This paper describes the symbolic execution of programs. Instead of supplying the normal inputs to a program (e.g. numbers) one supplies symbols representing arbitrary values. The execution proceeds as in a normal execution except that values may be symbolic formulas over the input symbols. The difficult, yet interesting issues arise during the symbolic execution of conditional branch type statements. A particular system called EFFIGY which provides symbolic execution for program testing and debugging is also described. It interpretively executes programs written in a simple PL/I style programming language. It includes many standard debugging features, the ability to manage and to prove things about symbolic expressions, a simple program testing manager, and a program verifier. A brief discussion of the relationship between symbolic execution and program proving is also included.},
  journal = {Commun. ACM},
  month = {jul},
  pages = {385–394},
  numpages = {10},
  keywords = {program debugging, program proving, program testing, program verification, symbolic execution, symbolic interpretation}
}

@article{Howden1977Dissect,
  author={Howden, W.E.},
  journal={IEEE Transactions on Software Engineering},
  title={Symbolic Testing and the DISSECT Symbolic Evaluation System},
  year={1977},
  volume={SE-3},
  number={4},
  pages={266-278},
  keywords={System testing;Programming profession;Software testing;Computer bugs;Data analysis;Error correction;Software reliability;Table lookup;Physics;Information science;Automated aids;data flow analysis;program correctness;program specifications;program testing;software errors;software reliability;symbolic evaluation;test data generation},
  doi={10.1109/TSE.1977.231144}
}

@article{Sen+2005Cute,
  author = {Sen, Koushik and Marinov, Darko and Agha, Gul},
  title = {CUTE: a concolic unit testing engine for C},
  year = {2005},
  issue_date = {September 2005},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {30},
  number = {5},
  issn = {0163-5948},
  url = {https://doi.org/10.1145/1095430.1081750},
  doi = {10.1145/1095430.1081750},
  abstract = {In unit testing, a program is decomposed into units which are collections of functions. A part of unit can be tested by generating inputs for a single entry function. The entry function may contain pointer arguments, in which case the inputs to the unit are memory graphs. The paper addresses the problem of automating unit testing with memory graphs as inputs. The approach used builds on previous work combining symbolic and concrete execution, and more specifically, using such a combination to generate test inputs to explore all feasible execution paths. The current work develops a method to represent and track constraints that capture the behavior of a symbolic execution of a unit with memory graphs as inputs. Moreover, an efficient constraint solver is proposed to facilitate incremental generation of such test inputs. Finally, CUTE, a tool implementing the method is described together with the results of applying CUTE to real-world examples of C code.},
  journal = {SIGSOFT Softw. Eng. Notes},
  month = {sep},
  pages = {263–272},
  numpages = {10},
  keywords = {concolic testing, data structure testing, explicit path model-checking, random testing, testing C programs, unit testing}
}

@inproceedings{Sen2007ConcolicTesting,
  author = {Sen, Koushik},
  title = {Concolic testing},
  year = {2007},
  isbn = {9781595938824},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1321631.1321746},
  doi = {10.1145/1321631.1321746},
  abstract = {Concolic testing automates test input generation by combining the concrete and symbolic (concolic) execution of the code under test. Traditional test input generation techniques use either (1) concrete execution or (2) symbolic execution that builds constraints and is followed by a generation of concrete test inputs from these constraints. In contrast, concolic testing tightly couples both concrete and symbolic executions: they run simultaneously, and each gets feedback from the other.We have implemented concolic testing in tools for testing both C and Java programs. We have used the tools to find bugs in several real-world software systems including SGLIB, a popular C data structure library used in a commercial tool, a third-party implementation of the Needham-Schroeder protocol and the TMN protocol, the scheduler of Honeywell's DEOS real-time operating system, and the Sun Microsystems' JDK 1.4 collection framework. In this tutorial, we will describe concolic testing and some of its recent extensions},
  booktitle = {Proceedings of the 22nd IEEE/ACM International Conference on Automated Software Engineering},
  pages = {571–572},
  numpages = {2},
  keywords = {unit testing, testing tools, testing C programs, symbolic execution, random testing, explicit path model-checking, data structure testing, concolic testing},
  location = {Atlanta, Georgia, USA},
  series = {ASE '07}
}

@article{Borzacchiello2021Fuzzolic,
  title = {FUZZOLIC: Mixing fuzzing and concolic execution},
  journal = {Computers \& Security},
  volume = {108},
  pages = {102368},
  year = {2021},
  issn = {0167-4048},
  doi = {https://doi.org/10.1016/j.cose.2021.102368},
  url = {https://www.sciencedirect.com/science/article/pii/S0167404821001929},
  author = {Luca Borzacchiello and Emilio Coppa and Camil Demetrescu},
  keywords = {Bug detection, Concolic execution, Fuzzing testing, SMT Solver, Hybrid fuzzing},
  abstract = {In the last few years, a large variety of approaches and methodologies have been explored in the context of software testing, ranging from black-box techniques, such as fuzzing, to white-box techniques, such as concolic execution, with a full spectrum of instances in between. Using these techniques, developers and security researchers have been able to identify in the last decade a large number of critical vulnerabilities in thousands of software projects. In this article, we investigate how to improve the performance and effectiveness of concolic execution, proposing two main enhancements to the original approach. On one side, we devise a novel concolic executor that can analyze complex binary programs while running under QEMU and efficiently produce symbolic queries, which could generate valuable program inputs when solved. On the other side, we investigate whether techniques borrowed from the fuzzing domain can be applied to solve the symbolic queries generated by concolic execution, providing a viable alternative to accurate but expensive SMT solving techniques. We show that the combination of our concolic engine, Fuzzolic, and our approximate solver, Fuzzy-Sat, can perform better in terms of code coverage than popular state-of-the-art fuzzers on a variety of complex programs and can identify different unknown bugs in several real-world applications.}
}

@article{Zhu+2022Fuzzing,
  author = {Zhu, Xiaogang and Wen, Sheng and Camtepe, Seyit and Xiang, Yang},
  title = {Fuzzing: A Survey for Roadmap},
  year = {2022},
  issue_date = {January 2022},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {54},
  number = {11s},
  issn = {0360-0300},
  url = {https://doi.org/10.1145/3512345},
  doi = {10.1145/3512345},
  abstract = {Fuzz testing (fuzzing) has witnessed its prosperity in detecting security flaws recently. It generates a large number of test cases and monitors the executions for defects. Fuzzing has detected thousands of bugs and vulnerabilities in various applications. Although effective, there lacks systematic analysis of gaps faced by fuzzing. As a technique of defect detection, fuzzing is required to narrow down the gaps between the entire input space and the defect space. Without limitation on the generated inputs, the input space is infinite. However, defects are sparse in an application, which indicates that the defect space is much smaller than the entire input space. Besides, because fuzzing generates numerous test cases to repeatedly examine targets, it requires fuzzing to perform in an automatic manner. Due to the complexity of applications and defects, it is challenging to automatize the execution of diverse applications. In this article, we systematically review and analyze the gaps as well as their solutions, considering both breadth and depth. This survey can be a roadmap for both beginners and advanced developers to better understand fuzzing.},
  journal = {ACM Comput. Surv.},
  month = {sep},
  articleno = {230},
  numpages = {36},
  keywords = {automation, input space, fuzzing theory, security, Fuzz testing}
}

@incollection{Li2011SymbexecTestGeneration,
  author = {Li, Guodong and Ghosh, Indradeep and Rajan, Sreeranga P.},
  title = {{KLOVER: A Symbolic Execution and Automatic Test Generation Tool for C++ Programs}},
  booktitle = {{Computer Aided Verification}},
  journal = {SpringerLink},
  pages = {609--615},
  year = {2011},
  issn = {1611-3349},
  isbn = {978-3-642-22110-1},
  publisher = {Springer},
  address = {Berlin, Germany},
  doi = {10.1007/978-3-642-22110-1_49}
}

@inproceedings{Daka+2014UnitTestingSurvey,
  author={Daka, Ermira and Fraser, Gordon},
  booktitle={2014 IEEE 25th International Symposium on Software Reliability Engineering},
  title={A Survey on Unit Testing Practices and Problems},
  year={2014},
  volume={},
  number={},
  pages={201-211},
  keywords={Testing;Software;Writing;Java;Reliability;Software engineering;unit testing;test case generation;survey},
  doi={10.1109/ISSRE.2014.11}
}

@misc{Sourceware2024GdbRemoteProtocol,
  title = {{Remote Protocol (Debugging with GDB)}},
  year = {2024},
  month = apr,
  note = {[Online; accessed 8. Apr. 2024]},
  url = {https://sourceware.org/gdb/current/onlinedocs/gdb.html/Remote-Protocol.html#Remote-Protocol}
}

@article{altman2000welcome,
  author={Altman, E.R. and Kaeli, D. and Sheffer, Y.},
  journal={Computer},
  title={Welcome to the opportunities of binary translation},
  year={2000},
  volume={33},
  number={3},
  pages={40-45},
  keywords={Software portability},
  doi={10.1109/2.825694}
}

@article{sites1993binary,
  author = {Sites, Richard L. and Chernoff, Anton and Kirk, Matthew B. and Marks, Maurice P. and Robinson, Scott G.},
  title = {Binary translation},
  year = {1993},
  issue_date = {Feb. 1993},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {36},
  number = {2},
  issn = {0001-0782},
  url = {https://doi.org/10.1145/151220.151227},
  doi = {10.1145/151220.151227},
  journal = {Commun. ACM},
  month = {feb},
  pages = {69–81},
  numpages = {13},
  keywords = {CISC computers, RISC computers, binary translation, computer architecture, processor architecture translation}
}

@inproceedings{probst2002dynamic,
  title={Dynamic binary translation},
  author={Probst, Mark},
  booktitle={UKUUG Linux Developer’s Conference},
  volume={2002},
  year={2002}
}

@inproceedings{cifuentes1996staticdynamic,
  author={Cifuentes and Malhotra},
  booktitle={1996 Proceedings of International Conference on Software Maintenance},
  title={Binary translation: static, dynamic, retargetable?},
  volume={},
  number={},
  pages={340-349},
  doi={10.1109/ICSM.1996.565037}
}

@inproceedings{Rocha2022Lasagne,
  author = {Rocha, Rodrigo C. O. and Sprokholt, Dennis and Fink, Martin and Gouicem, Redha and Spink, Tom and Chakraborty, Soham and Bhatotia, Pramod},
  title = {Lasagne: a static binary translator for weak memory model architectures},
  year = {2022},
  isbn = {9781450392655},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3519939.3523719},
  doi = {10.1145/3519939.3523719},
  abstract = {The emergence of new architectures create a recurring challenge to ensure that existing programs still work on them. Manually porting legacy code is often impractical. Static binary translation (SBT) is a process where a program’s binary is automatically translated from one architecture to another, while preserving their original semantics. However, these SBT tools have limited support to various advanced architectural features. Importantly, they are currently unable to translate concurrent binaries. The main challenge arises from the mismatches of the memory consistency model specified by the different architectures, especially when porting existing binaries to a weak memory model architecture. In this paper, we propose Lasagne, an end-to-end static binary translator with precise translation rules between x86 and Arm concurrency semantics. First, we propose a concurrency model for Lasagne’s intermediate representation (IR) and formally proved mappings between the IR and the two architectures. The memory ordering is preserved by introducing fences in the translated code. Finally, we propose optimizations focused on raising the level of abstraction of memory address calculations and reducing the number of fences. Our evaluation shows that Lasagne reduces the number of fences by up to about 65\%, with an average reduction of 45.5\%, significantly reducing their runtime overhead.},
  booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  pages = {888–902},
  numpages = {15},
  keywords = {Memory Model, Compiler, Binary Translation},
  location = {San Diego, CA, USA},
  series = {PLDI 2022}
}

@article{Sun+2023DbtBranchPred,
  AUTHOR = {Sun, Lianshan and Wu, Yanjin and Li, Linxiangyi and Zhang, Changbin and Tang, Jingyan},
  TITLE = {A Dynamic and Static Binary Translation Method Based on Branch Prediction},
  JOURNAL = {Electronics},
  VOLUME = {12},
  YEAR = {2023},
  NUMBER = {14},
  ARTICLE-NUMBER = {3025},
  URL = {https://www.mdpi.com/2079-9292/12/14/3025},
  ISSN = {2079-9292},
  ABSTRACT = {Binary translation is an important technique for achieving cross-architecture software migration. However, mainstream dynamic binary translation frameworks, such as QEMU, often generate a large amount of redundant code, which degrades the efficiency of the target code. To this end, we propose a dynamicâ€“static binary translation method based on branch prediction. It first identifies parts of translation blocks following static branch prediction techniques. Then it translates these translation blocks into less-redundant native code blocks by canonical static translation algorithms. Finally, it executes all code blocks that are translated either statically or dynamically by correctly maintaining and switching their running contexts. In order to correctly weave the two types of translation activities, the proposed method only translates the next translation block that is data-independent from the current one by the active variable analysis algorithm, and records and shares the intermediate states of the dynamic and static translation activities via a carefully designed data structure. In particular, a shadow register-based context recovery mechanism is proposed to correctly record the running context of static translation blocks, and to correctly recover the context for dynamically translating and running blocks that were not statically translated. We also designed an adaptive memory optimization mechanism to dynamically release the memory of the mispredicted translation blocks. We implemented a dynamicâ€“static binary translation framework by extending QEMU, called BP-QEMU (QEMU with branch prediction). We evaluated the translation correctness of BP-QEMU using the testing programs for the ARM and PPC instruction sets from QEMU, and evaluated the performance of BP-QEMU using the CoreMark benchmark code. The experimental results show that BP-QEMU can translate the instructions from the ARM and PPC architectures correctly; moreover, the average execution efficiency of the CoreMark code on BP-QEMU improves by 13.3\% compared to that of QEMU.},
  DOI = {10.3390/electronics12143025}
}

@inproceedings{Hawkins2015OptimizingDbt,
  author={Hawkins, Byron and Demsky, Brian and Bruening, Derek and Zhao, Qin},
  booktitle={2015 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)},
  title={Optimizing binary translation of dynamically generated code},
  year={2015},
  volume={},
  number={},
  pages={68-78},
  keywords={Optimization;Engines;Instruments;Benchmark testing;Security;Complexity theory;Data structures},
  doi={10.1109/CGO.2015.7054188}
}

@inproceedings{Kedia+2013DbtKernel,
  author = {Kedia, Piyus and Bansal, Sorav},
  title = {Fast dynamic binary translation for the kernel},
  year = {2013},
  isbn = {9781450323888},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2517349.2522718},
  doi = {10.1145/2517349.2522718},
  abstract = {Dynamic binary translation (DBT) is a powerful technique with several important applications. System-level binary translators have been used for implementing a Virtual Machine Monitor [2] and for instrumentation in the OS kernel [10]. In current designs, the performance overhead of binary translation on kernel-intensive workloads is high. e.g., over 10x slowdowns were reported on the syscall nanobenchmark in [2], 2-5x slowdowns were reported on lmbench microbenchmarks in [10]. These overheads are primarily due to the extra work required to correctly handle kernel mechanisms like interrupts, exceptions, and physical CPU concurrency.We present a kernel-level binary translation mechanism which exhibits near-native performance even on applications with large kernel activity. Our translator relaxes transparency requirements and aggressively takes advantage of kernel invariants to eliminate sources of slowdown. We have implemented our translator as a loadable module in unmodified Linux, and present performance and scalability experiments on multiprocessor hardware. Although our implementation is Linux specific, our mechanisms are quite general; we only take advantage of typical kernel design patterns, not Linux-specific features. For example, our translator performs 3x faster than previous kernel-level DBT implementations while running the Apache web server.},
  booktitle = {Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},
  pages = {101–115},
  numpages = {15},
  location = {Farminton, Pennsylvania},
  series = {SOSP '13}
}

@inproceedings{Guan+2010DbtOptimizations,
  author={Guan, Haibing and Yang, Hongbo and Qi, Zhengwei and Yang, Yindong and Liu, Bo},
  booktitle={2010 Proceedings of the 5th International Conference on Ubiquitous Information Technologies and Applications},
  title={The Optimizations in Dynamic Binary Translation},
  year={2010},
  volume={},
  number={},
  pages={1-6},
  keywords={Optimization;Registers;Resource management;Joining processes;Runtime;Binary codes;Instruction sets},
  doi={10.1109/ICUT.2010.5677870}
}

@misc{lldb2024Apr,
  title = {{xn--jo8h LLDB}},
  author = {The LLDB Team},
  year = {2024},
  month = apr,
  note = {[Online; accessed 12. Apr. 2024]},
  url = {https://lldb.llvm.org}
}

@manual{Intel2023DeveloperManualVol1,
    title={The Intel 64 and IA-32 Architectures Software Developer's Manual, Volume 1: Basic Architecture},
    author={Intel},
    year={2023},
}

@Inbook{Fraser2019SoftwareTesting,
  author="Fraser, Gordon
  and Rojas, Jos{\'e} Miguel",
  editor="Cha, Sungdeok
  and Taylor, Richard N.
  and Kang, Kyochul",
  title="Software Testing",
  bookTitle="Handbook of Software Engineering",
  year="2019",
  publisher="Springer International Publishing",
  address="Cham",
  pages="123--192",
  abstract="Any nontrivial program contains some errors in the source code. These ``bugs'' are annoying for users if they lead to application crashes and data loss, and they are worrisome if they lead to privacy leaks and security exploits. The economic damage caused by software bugs can be huge, and when software controls safety critical systems such as automotive software, then bugs can kill people. The primary tool to reveal and eliminate bugs is software testing: Testing a program means executing it with a selected set of inputs and checking whether the program behaves in the expected way; if it does not, then a bug has been detected. The aim of testing is to find as many bugs as possible, but it is a difficult task as it is impossible to run all possible tests on a program. The challenge of being a good tester is thus to identify which are the best tests that help us find bugs, and to execute them as efficiently as possible. In this chapter, we explore different ways to measure how ``good'' a set of tests is, as well as techniques to generate good sets of tests.",
  isbn="978-3-030-00262-6",
  doi="10.1007/978-3-030-00262-6_4",
  url="https://doi.org/10.1007/978-3-030-00262-6_4"
}

@article{Garousi+2016SoftwareTestingLitRev,
  title = {A systematic literature review of literature reviews in software testing},
  journal = {Information and Software Technology},
  volume = {80},
  pages = {195-216},
  year = {2016},
  issn = {0950-5849},
  doi = {https://doi.org/10.1016/j.infsof.2016.09.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0950584916301446},
  author = {Vahid Garousi and Mika V. Mäntylä},
  keywords = {Secondary studies, Tertiary study, Software testing, Systematic mapping, Systematic literature reviews, Surveys},
  abstract = {Context
  Any newcomer or industrial practitioner is likely to experience difficulties in digesting large volumes of knowledge in software testing. In an ideal world, all knowledge used in industry, education and research should be based on high-quality evidence. Since no decision should be made based on a single study, secondary studies become essential in presenting the evidence. According to our search, over 101 secondary studies have been published in the area of software testing since 1994. With this high number of secondary studies, it is important to conduct a review in this area to provide an overview of the research landscape in this area.
  Objective
  The goal of this study is to systematically map (classify) the secondary studies in software testing. We propose that tertiary studies can serve as summarizing indexes which facilitate finding the most relevant information from secondary studies and thus supporting evidence-based decision making in any given area of software engineering. Our research questions (RQs) investigate: (1) Software-testing-specific areas, (2) Types of RQs investigated, (3) Numbers and Trends, and (4) Citations of the secondary studies.
  Method
  To conduct the tertiary study, we use the systematic-mapping approach. Additionally, we contrast the testing topics to the number of Google hits to address a general popularity of a testing topic and study the most popular papers in terms of citations. We furthermore demonstrate the practicality and usefulness of our results by mapping them to ISTQB foundation syllabus and to SWEBOK to provide implications for practitioners, testing educators, and researchers.
  Results
  After a systematic search and voting process, our study pool included 101 secondary studies in the area of software testing between 1994 and 2015. Among our results are the following: (1) In terms of number of secondary studies, model-based approach is the most popular testing method, web services are the most popular system under test (SUT), while regression testing is the most popular testing phase; (2) The quality of secondary studies, as measured by a criteria set established in the community, is slowly increasing as the years go by; and (3) Analysis of research questions, raised and studied in the pool of secondary studies, showed that there is a lack of ‘causality’ and ‘relationship’ type of research questions, a situation which needs to be improved if we, as a community, want to advance as a scientific field. (4) Among secondary studies, we found that regular surveys receive significantly more citations than SMs (p=0.009) and SLRs (p=0.014).
  Conclusion
  Despite the large number of secondary studies, we found that many important areas of software testing currently lack secondary studies, e.g., test management, role of product risk in testing, human factors in software testing, beta-testing (A/B-testing), exploratory testing, testability, test stopping criteria, and test-environment development. Having secondary studies in those areas is important for satisfying industrial and educational needs in software testing. On the other hand, education material of ISTQB foundation syllabus and SWEBOK could benefit from the inclusion of the latest research topics, namely search-based testing, use of cloud-computing for testing and symbolic execution.}
}

@inproceedings{Martignoni+2009TestingCpuEmulators,
  author = {Martignoni, Lorenzo and Paleari, Roberto and Roglia, Giampaolo Fresi and Bruschi, Danilo},
  title = {Testing CPU emulators},
  year = {2009},
  isbn = {9781605583389},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1572272.1572303},
  doi = {10.1145/1572272.1572303},
  abstract = {A CPU emulator is a software that simulates a hardware CPU. Emulators are widely used by computer scientists for various kind of activities (e.g., debugging, profiling, and malware analysis). Although no theoretical limitation prevents to develop an emulator that faithfully emulates a physical CPU, writing a fully featured emulator is a very challenging and error-prone task. Modern CISC architectures have a very rich instruction set, some instructions lack proper specifications, and others may have undefined effects in corner-cases. This paper presents a testing methodology specific for CPU emulators, based on fuzzing. The emulator is "stressed" with specially crafted test-cases, to verify whether the CPU is properly emulated or not. Improper behaviours of the emulator are detected by running the same test-case concurrently on the emulated and on the physical CPUs and by comparing the state of the two after the execution. Differences in the final state testify defects in the code of the emulator. We implemented this methodology in a prototype (codenamed EmuFuzzer), analysed four state-of-the-art IA-32 emulators (QEMU, Valgrind, Pin and BOCHS), and found several defects in each of them, some of which can prevent the proper execution of programs.},
  booktitle = {Proceedings of the Eighteenth International Symposium on Software Testing and Analysis},
  pages = {261–272},
  numpages = {12},
  keywords = {automatic test generation, emulation, fuzzing, software testing},
  location = {Chicago, IL, USA},
  series = {ISSTA '09}
}

@inproceedings{Ma+2010PrototypingAndTestingEmulators,
  author={Ma, Weiqin and Forin, Alessandro and Liu, Jyh-Charn},
  booktitle={Proceedings of 2010 21st IEEE International Symposium on Rapid System Protyping},
  title={Rapid prototyping and compact testing of CPU emulators},
  year={2010},
  volume={},
  number={},
  pages={1-7},
  keywords={Registers;Testing;Manuals;Routing;Generators;Hardware;Software;Microprocessors;Simulation software;Testing},
  doi={10.1109/RSP.2010.5656339}
}

@article{Martignoni+2012PokeEmu,
  author = {Martignoni, Lorenzo and McCamant, Stephen and Poosankam, Pongsin and Song, Dawn and Maniatis, Petros},
  title = {Path-exploration lifting: hi-fi tests for lo-fi emulators},
  year = {2012},
  issue_date = {March 2012},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {40},
  number = {1},
  issn = {0163-5964},
  url = {https://doi.org/10.1145/2189750.2151012},
  doi = {10.1145/2189750.2151012},
  abstract = {Processor emulators are widely used to provide isolation and instrumentation of binary software. However they have proved difficult to implement correctly: processor specifications have many corner cases that are not exercised by common workloads. It is untenable to base other system security properties on the correctness of emulators that have received only ad-hoc testing. To obtain emulators that are worthy of the required trust, we propose a technique to explore a high-fidelity emulator with symbolic execution, and then lift those test cases to test a lower-fidelity emulator. The high-fidelity emulator serves as a proxy for the hardware specification, but we can also further validate by running the tests on real hardware. We implement our approach and apply it to generate about 610,000 test cases; for about 95\% of the instructions we achieve complete path coverage. The tests reveal thousands of individual differences; we analyze those differences to shed light on a number of root causes, such as atomicity violations and missing security features.},
  journal = {SIGARCH Comput. Archit. News},
  month = {mar},
  pages = {337–348},
  numpages = {12},
  keywords = {CPU emulators, cross validation, symbolic binary execution}
}


@inproceedings{Kim+2017TestBinaryLifters,
  author={Kim, Soomin and Faerevaag, Markus and Jung, Minkyu and Jung, Seungll and Oh, DongYeop and Lee, JongHyup and Cha, Sang Kil},
  booktitle={2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  title={Testing intermediate representations for binary analysis},
  year={2017},
  volume={},
  number={},
  pages={353-364},
  keywords={Semantics;Computer bugs;Binary codes;Testing;Tools;Software;C++ languages},
  doi={10.1109/ASE.2017.8115648}
}

@inproceedings{Dasgupta+2020CompLifter,
  author = {Dasgupta, Sandeep and Dinesh, Sushant and Venkatesh, Deepan and Adve, Vikram S. and Fletcher, Christopher W.},
  title = {Scalable validation of binary lifters},
  year = {2020},
  isbn = {9781450376136},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3385412.3385964},
  doi = {10.1145/3385412.3385964},
  abstract = {Validating the correctness of binary lifters is pivotal to gain trust in binary analysis, especially when used in scenarios where correctness is important. Existing approaches focus on validating the correctness of lifting instructions or basic blocks in isolation and do not scale to full programs. In this work, we show that formal translation validation of single instructions for a complex ISA like x86-64 is not only practical, but can be used as a building block for scalable full-program validation. Our work is the first to do translation validation of single instructions on an architecture as extensive as x86-64, uses the most precise formal semantics available, and has the widest coverage in terms of the number of instructions tested for correctness. Next, we develop a novel technique that uses validated instructions to enable program-level validation, without resorting to performance-heavy semantic equivalence checking. Specifically, we compose the validated IR sequences using a tool we develop called Compositional Lifter to create a reference standard. The semantic equivalence check between the reference and the lifter output is then reduced to a graph-isomorphism check through the use of semantic preserving transformations. The translation validation of instructions in isolation revealed 29 new bugs in McSema – a mature open-source lifter from x86-64 to LLVM IR. Towards the validation of full programs, our approach was able to prove the translational correctness of 2254/2348 functions taken from LLVM’s single-source benchmark test-suite.},
  booktitle = {Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages = {655–671},
  numpages = {17},
  keywords = {x86-64, Translation Validation, LLVM IR, Graph Isomorphism, Formal Semantics, Compiler Optimizations},
  location = {London, UK},
  series = {PLDI 2020}
}
